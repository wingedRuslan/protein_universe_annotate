{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9n1hzmoE9onA"
   },
   "source": [
    "# Use trained model from the publication \"Using Deep Learning to Annotate the Protein Universe\".\n",
    "[preprint link](https://doi.org/10.1101/626507)\n",
    "\n",
    "This notebook used to calculate the embeddings of the protein sequence using trained ProtCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcuZsUQjt2je",
    "outputId": "7faf1763-62a2-4d4e-9f96-e61648fda606"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yK5AUTABPi5a"
   },
   "outputs": [],
   "source": [
    "# !pip install -e /content/drive/MyDrive/_ruslan_project/protein_universe_annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VlQdwu4aP_TT"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/content/drive/MyDrive/_ruslan_project/protein_universe_annotate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YmDU-JpQPbf6"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "# Suppress noisy log messages.\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from protein_universe_annotate.utils import get_top_k_values_indices\n",
    "from protein_universe_annotate.constants import AMINO_ACID_VOCABULARY, _PFAM_GAP_CHARACTER\n",
    "from protein_universe_annotate.data_processing import read_pfam_dataset\n",
    "from protein_universe_annotate.inference.inference_misc import infer_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from protein_universe_annotate.inference.inference_ProtCNN import residues_to_one_hot, pad_one_hot_sequence, batch_iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pca8JUJH9GyK"
   },
   "source": [
    "## Library functions: convert sequence to one-hot array (input to model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egM-2RHJ9Bnm"
   },
   "source": [
    "## Download model and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Up68255TDGKe",
    "outputId": "4db818ac-da43-4218-d99a-394a21033f26"
   },
   "outputs": [],
   "source": [
    "# Get a TensorFlow SavedModel\n",
    "# !wget -qN https://storage.googleapis.com/brain-genomics-public/research/proteins/pfam/models/single_domain_per_sequence_zipped_models/seed_random_32.0/5356760.tar.gz\n",
    "# unzip\n",
    "# !tar xzf 5356760.tar.gz\n",
    "# Get the vocabulary for the model, which tells you which output index means which family\n",
    "# !wget https://storage.googleapis.com/brain-genomics-public/research/proteins/pfam/models/single_domain_per_sequence_zipped_models/trained_model_pfam_32.0_vocab.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYaOgeZx9JrV"
   },
   "source": [
    "## Load the model into TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rwQj9z1UR-F-"
   },
   "outputs": [],
   "source": [
    "model_path = '/models/trn-_cnn_random__random_sp_gpu-cnn_for_random_pfam-5356760'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Bp1imZTA6L_0"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zbZfobaq6bkI"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    trained_model = tf.saved_model.load(sess, ['serve'], model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR0Gl4Mx9Mgm"
   },
   "source": [
    "## Load tensors for getting the embedding of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zbapL8YS7FpE"
   },
   "outputs": [],
   "source": [
    "sequence_input_tensor_name = trained_model.signature_def['confidences'].inputs['sequence'].name\n",
    "sequence_lengths_input_tensor_name = trained_model.signature_def['confidences'].inputs['sequence_length'].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9iUCIO99QPs"
   },
   "source": [
    "## Compute embedding on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AB_fZuxm8KL8"
   },
   "outputs": [],
   "source": [
    "# Get embedding for globin_domain\n",
    "hemoglobin = 'MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHGKKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTPAVHASLDKFLASVSTVLTSKYR'\n",
    "globin_domain = hemoglobin[6:107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_FRCNv3G9-hw"
   },
   "outputs": [],
   "source": [
    "embedding_signature = trained_model.signature_def['pooled_representation']\n",
    "embedding_signature_tensor_name = embedding_signature.outputs['output'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Dfh4JW3x9-h9"
   },
   "outputs": [],
   "source": [
    "# The first run of this cell will be slower; the subsequent runs will be fast.\n",
    "# This is because on the first run, the TensorFlow XLA graph is compiled, and\n",
    "# then is reused.\n",
    "with graph.as_default():\n",
    "    embedding = sess.run(\n",
    "        embedding_signature_tensor_name,\n",
    "        {\n",
    "            # Note that this function accepts a batch of sequences which\n",
    "            # can speed up inference when running on many sequences.\n",
    "            sequence_input_tensor_name: [residues_to_one_hot(globin_domain)],\n",
    "            sequence_lengths_input_tensor_name: [len(globin_domain)],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hZ7rqXbTs6u",
    "outputId": "106ae456-5fd2-4205-9736-d316508982ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of embedding is (# seqs in batch, number of features in embedding space)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sjy8fjvTzc9",
    "outputId": "f72d7cd2-1cea-4553-f16d-09bd92da4329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17.9971   ,   1.3453426, -43.63362  , ...,  -9.863431 ,\n",
       "        -33.738045 ,  23.25798  ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "O5tR7gWbLESZ"
   },
   "outputs": [],
   "source": [
    "def calc_embeddings(batch):\n",
    "    \n",
    "    seq_lens = [len(seq) for seq in batch]\n",
    "    one_hots = [residues_to_one_hot(seq) for seq in batch]\n",
    "    padded_sequence_inputs = [pad_one_hot_sequence(seq, max(seq_lens)) for seq in one_hots]\n",
    "\n",
    "    with graph.as_default():\n",
    "        return sess.run(\n",
    "            embedding_signature_tensor_name,\n",
    "            {\n",
    "                sequence_input_tensor_name: padded_sequence_inputs,\n",
    "                sequence_lengths_input_tensor_name: seq_lens,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiB7mfsSTehD"
   },
   "source": [
    "## Compute embeddings for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HlQmx5L3x-q",
    "outputId": "b14d48ef-8f56-4ae4-c387-dd67593bc5d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dataset partitions:  ['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "data_partitions_dirpath = '../data/'\n",
    "print('Available dataset partitions: ', os.listdir(data_partitions_dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "exxIPNK4S-8h"
   },
   "outputs": [],
   "source": [
    "test_df = read_pfam_dataset('test', data_partitions_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "N69itIcv3xpx"
   },
   "outputs": [],
   "source": [
    "# Sort test_df by sequence length so that batches have as little padding as \n",
    "# possible -> faster forward pass\n",
    "test_df = test_df.sort_values('sequence', key=lambda col: [len(c) for c in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEvEzIY4NMk3",
    "outputId": "dbf3d863-b551-4443-886d-d740f65f7548"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7886/7886 [14:26<00:00,  9.10it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_testset = []\n",
    "\n",
    "batches = list(batch_iterable(test_df.sequence, 16))\n",
    "\n",
    "for seq_batch in tqdm.tqdm(batches, position=0):\n",
    "    batch_embeddings = calc_embeddings(seq_batch)\n",
    "    embeddings_testset.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfQUzYS8RthO",
    "outputId": "aec3b890-4889-47ef-88d8-2c34fa5b87c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126171"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noP3B11JSUQu"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/_ruslan_project/testset_embeddings.npy', 'wb') as f:\n",
    "    np.save(f, np.array(embeddings_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW3-BBOhS3-_"
   },
   "source": [
    "## Compute the embeddings of the training data (e.g. to fit the KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaEr7nDbTOqt"
   },
   "outputs": [],
   "source": [
    "train_df = read_pfam_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoqbwOn-TYmI"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values('sequence', key=lambda col: [len(c) for c in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CcZJmAPMmbw"
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNmYIqXfT5Qz"
   },
   "outputs": [],
   "source": [
    "batches = list(batch_iterable(train_df.sequence, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oYsh4lon8zY"
   },
   "outputs": [],
   "source": [
    "# Keep embeddings of the train dataset in predefined size list\n",
    "embeddings_trainset = [0] * len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzSBFUOW4DSE",
    "outputId": "5a2a2043-7c68-45eb-f6a5-bac6d5d5a799"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 29999/67922 [19:34<33:28, 18.88it/s]<ipython-input-54-43efd62225cb>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.save(f, np.array(embeddings_trainset))\n",
      "100%|██████████| 67922/67922 [1:25:18<00:00, 13.27it/s]\n"
     ]
    }
   ],
   "source": [
    "count_batches = 0\n",
    "curr_batch_position = 0\n",
    "\n",
    "for seq_batch in tqdm.tqdm(batches, position=0):\n",
    "    batch_embeddings = calc_embeddings(seq_batch)\n",
    "    embeddings_trainset[curr_batch_position : curr_batch_position + batch_size] = batch_embeddings\n",
    "    \n",
    "    count_batches += 1\n",
    "    curr_batch_position += batch_size\n",
    "\n",
    "    # Process in blocks since embeddings_trainset is too huge to keep in limited RAM\n",
    "    # embeddings_trainset, (len(train_data), 1100), where embedding of length 1100\n",
    "    # if count_batches % 30000 == 0:\n",
    "    #     with open(f'/content/drive/MyDrive/_ruslan_project/trainset_embeddings_{count_batches}.npy', 'wb') as f:\n",
    "    #         np.save(f, np.array(embeddings_trainset))\n",
    "    #     embeddings_trainset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wenzkbBFQzcn"
   },
   "outputs": [],
   "source": [
    "with open(f'/content/drive/MyDrive/_ruslan_project/trainset_embeddings.npy', 'wb') as f:\n",
    "    np.save(f, np.array(embeddings_trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z97xgYNtUMj1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PV273E_sV--A",
    "outputId": "fce80dd0-2463-48ff-b736-a7e51e4c4fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3451133952"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the available RAM memory\n",
    "import psutil\n",
    "psutil.virtual_memory().available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwAgv-sxW4fP"
   },
   "outputs": [],
   "source": [
    "# Free up RAM memory\n",
    "# del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6eTb_U6epcM"
   },
   "outputs": [],
   "source": [
    "embeddings_train_1 = np.load('/content/drive/MyDrive/_ruslan_project/trainset_embeddings_3000.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PN5oDDzepTh"
   },
   "outputs": [],
   "source": [
    "embeddings_train_2 = np.load('/content/drive/MyDrive/_ruslan_project/trainset_embeddings_60000.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVLP8SHulTWh"
   },
   "outputs": [],
   "source": [
    "embeddings_train_3 = np.load('/content/drive/MyDrive/_ruslan_project/trainset_embeddings_remaining.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVIxekd8hxa1",
    "outputId": "a9099966-c9ba-4fd2-c6ef-e7a64c7c1623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPErQC-Dji2N",
    "outputId": "fb7fa0e4-0f47-4d64-f971-a5124e0eef69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train_2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlDp9aTokOYB",
    "outputId": "b05844f8-dae1-4e52-b8e9-0aef96fbfcff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train_3.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUFMe_eAkORQ"
   },
   "outputs": [],
   "source": [
    "# Convert the dtype of the array from float64 to float32 -->\n",
    "# Save memory on disk and RAM\n",
    "embeddings_train_1 = embeddings_train_1.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0bMKZwLkOKr"
   },
   "outputs": [],
   "source": [
    "# Concatenate the arrays along the first axis\n",
    "train_embeddings = np.concatenate((embeddings_train_1, embeddings_train_2, embeddings_train_3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZLYLnXhmI7X",
    "outputId": "37c6ae47-6c75-4512-d8f2-8cdaefcbe895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 4560.15 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage: {train_embeddings.nbytes / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toUQGCRLmJGm"
   },
   "outputs": [],
   "source": [
    "with open(f'/content/drive/MyDrive/_ruslan_project/training_embeddings.npy', 'wb') as f:\n",
    "    np.save(f, train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2S0lxjhXP_g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "protein-cls",
   "language": "python",
   "name": "protein-cls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
